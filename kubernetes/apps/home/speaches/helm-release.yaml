---
# yaml-language-server: $schema=https://raw.githubusercontent.com/bjw-s/helm-charts/main/charts/other/app-template/schemas/helmrelease-helm-v2.schema.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: speaches
  namespace: home
spec:
  interval: 5m
  upgrade:
    force: true
  chart:
    spec:
      chart: app-template
      version: 4.4.0
      sourceRef:
        kind: HelmRepository
        name: bjw-s
        namespace: flux-system
      interval: 5m
  values:
    controllers:
      main:
        containers:
          main:
            image:
              repository: ghcr.io/speaches-ai/speaches
              tag: 0.9.0-rc.2-cuda-12.6.3
            env:
              NVIDIA_VISIBLE_DEVICES: all
            lifecycle:
              postStart:
                exec:
                  command:
                    - /bin/bash
                    - -c
                    - |
                      curl -LsSf https://astral.sh/uv/install.sh | sh # https://github.com/speaches-ai/speaches/issues/416
                      uvx speaches-cli model download speaches-ai/Kokoro-82M-v1.0-ONNX
                      uvx speaches-cli model download Systran/faster-whisper-medium.en
                      uvx speaches-cli model download speaches-ai/piper-en_US-hfc_female-medium
                      uvx speaches-cli model download speaches-ai/Kokoro-82M-v1.0-ONNX-int8
                      uvx speaches-cli model download speaches-ai/Kokoro-82M-v1.0-ONNX-fp16
                      uvx speaches-cli model download suronek/Kokoro-82M-v1.1-zh-ONNX
        pod:
          runtimeClassName: nvidia
          nodeSelector:
            kubernetes.io/hostname: worker04
          tolerations:
            - key: gpu
              operator: Exists

    service:
      main:
        controller: main
        ports:
          http:
            port: 8000

    persistence:
      downloads:
        type: emptyDir
        globalMounts:
          - path: /home/ubuntu/.cache/huggingface/hub/
